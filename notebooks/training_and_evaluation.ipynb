{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e223bfbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     17\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m../\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     load_and_preprocess_image,\n\u001b[32m     20\u001b[39m     augment_image,\n\u001b[32m     21\u001b[39m     prepare_datasets,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     load_config,\n\u001b[32m     25\u001b[39m     build_cnn_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     log_experiment_mflow,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     31\u001b[39m     evaluate_model,\n\u001b[32m     32\u001b[39m     plot_confusion_matrix,\n\u001b[32m     33\u001b[39m     save_classification_report,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ltolu\\OneDrive\\Desktop\\gtsrb-traffic-signs\\notebooks\\..\\src\\data\\preprocess.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, DirectoryIterator\n\u001b[32m      7\u001b[39m logging.basicConfig(level=logging.INFO)\n\u001b[32m      8\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# EDA (dataset overview, visualizations)\n",
    "# Preprocessing pipeline (resize, normalize, augment)\n",
    "# Model building & training (CNN in TensorFlow)\n",
    "# Evaluation (metrics + confusion matrix)\n",
    "# Save model + artifacts\n",
    "# MLflow experiment logging\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data.preprocess import (\n",
    "    load_and_preprocess_image,\n",
    "    augment_image,\n",
    "    prepare_datasets,\n",
    ")\n",
    "from src.models.train import (\n",
    "    load_config,\n",
    "    build_cnn_model,\n",
    "    build_transfer_model,\n",
    "    train_and_evaluate,\n",
    "    log_experiment_mflow,\n",
    ")\n",
    "from src.models.evaluate import (\n",
    "    evaluate_model,\n",
    "    plot_confusion_matrix,\n",
    "    save_classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1105a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/raw/\"\n",
    "train_dir = \"../data/raw/train/\"\n",
    "test_dir = \"../data/raw/test/\"\n",
    "config = load_config(\"../config.yaml\")\n",
    "# walk through folders\n",
    "# store imgae path + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of images per class\n",
    "# Plt bar chart\n",
    "# Show a grid of sample images for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images to 128x128\n",
    "# normalize pixel vales (0-1)   Data Normalization\n",
    "# split into train/val/test sets\n",
    "# optionally use sklearn train_test_split\n",
    "\n",
    "images_data = load_and_preprocess_image(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ImageDatagenerator for augmentation (rotation, zoom, flips)\n",
    "# Create train/validation/test iterators\n",
    "# rotation_range=15, brightness_range=[0.8, 1.2], horizontal_flip=False\n",
    "\n",
    "augment_image_data = augment_image(images_data)\n",
    "\n",
    "train_data, val_data, test_data, class_names = prepare_datasets(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7425398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "# Conv2D → MaxPooling → Conv2D → MaxPooling → Flatten → Dense → Dropout → Output (Softmax with 4 classes)\n",
    "model = build_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf6eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = build_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with Adam optimizer\n",
    "# Loss: categorical_crossentropy\n",
    "# Metrics: accuracy\n",
    "# Train model for N epochs with validation set\n",
    "# Store training history\n",
    "history, eval_metrics = train_and_evaluate(model, train_data, val_data, test_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy & loss over epochs\n",
    "# Use matplotlib to plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "# Print classification_report\n",
    "# Plot confusion matrix\n",
    "cm, report = evaluate_model(history, test_data, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to models/cnn_grapevine.h5\n",
    "# Save plots (accuracy/loss, confusion matrix) into reports/\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "save_classification_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6289ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow run\n",
    "# Log parameters: batch_size, epochs, learning_rate\n",
    "# Log final accuracy & loss\n",
    "# Log saved model\n",
    "metrics = [\"accuracy\", \"loss\"]\n",
    "log_experiment_mflow(model, history, [\"accuracy\", \"loss\"], config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
